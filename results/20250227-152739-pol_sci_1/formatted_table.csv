Model,Median Grade Received,Grading Bias
GPT-3.5-Turbo,B+ (87),Neutral (90)
Llama-3-8B,B+ (87),Strict (-1 grade)
GPT-4o-mini,A- (90),Strict (-1 grade)
Claude-3-Sonnet,B+ (87),Slightly Lenient (+1/3)
GPT-4o,B+ (87),Neutral (90)
grok-beta,B+ (87),Strict (-1 grade)
Claude-3.7-Sonnet,A- (90),Strict (-1 grade)
Qwen-Turbo,A- (90),Strict (-1 grade)
Gemini Flash 2.0,A- (90),Strict (-1 grade)
o1,B+ (87),Neutral (90)
grok2-1212,A- (90),Neutral (90)
Claude-3-Opus,B+ (87),Neutral (90)
o1-mini,A- (90),Strict (-1 grade)
Perplexity: Llama 3.1 Sonar 70B,A- (90),Neutral (90)
Gemini Pro 1.5,A- (90),Very Strict (-2 grades)
Perplexity: Llama 3.1 Sonar 8B Online,B+ (87),Strict (-1 grade)
Qwen-Plus,A- (90),Neutral (90)
o3-mini-high,A- (90),Neutral (90)
Qwen-Max,B+ (87),Strict (-1 grade)
DeepSeek-Distill-Qwen-32b,A- (90),Neutral (90)
DeepSeek-R1-Full,A- (90),Neutral (90)
Claude-3.7-Sonnet-thinking,A- (90),Strict (-1 grade)